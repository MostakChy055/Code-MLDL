{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHFQgwLzugw4"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "devDs = pd.read_csv('//content/CT24_checkworthy_dutch_dev-test.tsv', sep = '\\t')\n",
        "testtDs = pd.read_csv('/content/CT24_checkworthy_dutch_dev.tsv', sep = '\\t')\n",
        "trainDs = pd.read_csv('/content/CT24_checkworthy_dutch_train.tsv', sep = '\\t')\n",
        "testDs = pd.read_csv('/content/CT24_checkworthy_dutch_test_gold.tsv', sep = '\\t')\n",
        "\n",
        "df = pd.concat([devDs, testtDs, trainDs], ignore_index = True)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "V7BE876-u9R0",
        "outputId": "ab0b8a4f-247d-4474-df80-87218f90de6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              tweet_id                                          tweet_url  \\\n",
              "0  1256120472875524096  http://twitter.com/user/status/125612047287552...   \n",
              "1  1256154134027350019  http://twitter.com/user/status/125615413402735...   \n",
              "2  1256253220239872000  http://twitter.com/user/status/125625322023987...   \n",
              "3  1256305038139576326  http://twitter.com/user/status/125630503813957...   \n",
              "4  1256487670311682048  http://twitter.com/user/status/125648767031168...   \n",
              "\n",
              "                                          tweet_text class_label  \n",
              "0  Ik merk op da  \"kleinere\" supermark en me  voo...         Yes  \n",
              "1  Vanaf maandag 4 mei dragen we een mondmasker o...          No  \n",
              "2  @evaverhoevenph1 Er is bij mijn we en geen enk...         Yes  \n",
              "3  De #Volkskran  29 april: In #Nederland zijn  b...          No  \n",
              "4  Hoe ro  en ongewens  de si ua ie waarin we me ...          No  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8c6a387-4e24-4676-8b85-53abf361737c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet_url</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>class_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1256120472875524096</td>\n",
              "      <td>http://twitter.com/user/status/125612047287552...</td>\n",
              "      <td>Ik merk op da  \"kleinere\" supermark en me  voo...</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1256154134027350019</td>\n",
              "      <td>http://twitter.com/user/status/125615413402735...</td>\n",
              "      <td>Vanaf maandag 4 mei dragen we een mondmasker o...</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1256253220239872000</td>\n",
              "      <td>http://twitter.com/user/status/125625322023987...</td>\n",
              "      <td>@evaverhoevenph1 Er is bij mijn we en geen enk...</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1256305038139576326</td>\n",
              "      <td>http://twitter.com/user/status/125630503813957...</td>\n",
              "      <td>De #Volkskran  29 april: In #Nederland zijn  b...</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1256487670311682048</td>\n",
              "      <td>http://twitter.com/user/status/125648767031168...</td>\n",
              "      <td>Hoe ro  en ongewens  de si ua ie waarin we me ...</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8c6a387-4e24-4676-8b85-53abf361737c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b8c6a387-4e24-4676-8b85-53abf361737c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b8c6a387-4e24-4676-8b85-53abf361737c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c39c5bf8-75f8-4aae-836e-4b4cd6ced7cc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c39c5bf8-75f8-4aae-836e-4b4cd6ced7cc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c39c5bf8-75f8-4aae-836e-4b4cd6ced7cc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1913,\n  \"fields\": [\n    {\n      \"column\": \"tweet_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51357195317405944,\n        \"min\": 1224044613528444928,\n        \"max\": 1399355541357531141,\n        \"num_unique_values\": 1913,\n        \"samples\": [\n          1241009786461790213,\n          1386266171167715330,\n          1238175813792608256\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1913,\n        \"samples\": [\n          \"http://twitter.com/user/status/1241009786461790213\",\n          \"http://twitter.com/user/status/1386266171167715330\",\n          \"http://twitter.com/user/status/1238175813792608256\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1913,\n        \"samples\": [\n          \"Het ziet er overigens naar uit dat vanwege #Covid_19 premier Netanyahu als premier van een nationaal noodkabinet uit de bus zal komen. Dit zal het einde van Gantz en Blauw Wit betekenen. En de Isra\\u00eblische democratie bevindt zich al op het randje. https://t.co/Az9EMorN3A\",\n          \"@Har vNL De grens is bereik  Me  koningsdag in he  verschie  liggen ui  ons dorp mensen  ussen de 25  /m 60 jaar op de ic van he  ziekenhuis #zorgelijk #corona\",\n          \"Veldman (VVD) tijdens #coronadebat: het heeft geen zin om maatregelen te nemen die niet bij de fase passen.. Wat een ontzettend dom en bureaucratisch gelul.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_indices = df[df['class_label'] == \"NO\"].index[:100]  # Select only the first 100 indices\n",
        "df = df.drop(no_indices)\n",
        "df['class_label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pwz1ECPY3nwP",
        "outputId": "a6f91a71-7d19-41aa-f4e2-fb0982e72cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "class_label\n",
              "No     1090\n",
              "Yes     823\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLikAO0Evq4n",
        "outputId": "4b93a1fa-f654-465c-925b-35f5309eb14c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import sent_tokenize\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "story = []\n",
        "for index, row in df.iterrows():\n",
        "  text = row['tweet_text']\n",
        "  raw_sent = sent_tokenize(text)\n",
        "  for sent in raw_sent:\n",
        "        story.append(simple_preprocess(sent))"
      ],
      "metadata": {
        "id": "l7qZJNj7vtWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vecModel = gensim.models.Word2Vec(\n",
        "    window=10,\n",
        "    min_count=2\n",
        ")"
      ],
      "metadata": {
        "id": "2XnIdvqSvxaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vecModel.build_vocab(story)"
      ],
      "metadata": {
        "id": "7kdJr4WFv4nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vecModel.train(story, total_examples = word2vecModel.corpus_count, epochs = word2vecModel.epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ0Wpfa7v6F6",
        "outputId": "4344405e-2bb5-4208-b012-031565875d69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(174760, 276755)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['class_label'] = df['class_label'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "df2 = testDs\n",
        "df2['class_label'] = df2['class_label'].apply(lambda x: 1 if x == 'Yes' else 0)"
      ],
      "metadata": {
        "id": "B4UVnYHKv7nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDBwW1dmv_pr",
        "outputId": "012cfec9-a04f-42ac-d38f-02f8c4743c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.25.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.16.0)\n",
            "Installing collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Bidirectional, GRU, MultiHeadAttention, LayerNormalization, Concatenate, GlobalAveragePooling1D\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import f1_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "from keras.callbacks import EarlyStopping\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "def get_word_embedding_model(word_embedding_type):\n",
        "    if word_embedding_type == \"word2vec\":\n",
        "        word_embedding_model = word2vecModel\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported word embedding type. Choose 'word2vec' or 'fasttext'.\")\n",
        "    return word_embedding_model\n",
        "\n",
        "def get_sentence_embedding(sentence, model, word_embedding_type):\n",
        "    if word_embedding_type == \"word2vec\":\n",
        "        tokens = word_tokenize(sentence.lower())\n",
        "        vectors = [model.wv[token] for token in tokens if token in model.wv]\n",
        "        if not vectors:\n",
        "            return np.zeros(model.vector_size)\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported word embedding type. Choose 'word2vec' or 'fasttext'.\")\n",
        "\n",
        "def create_embedding_matrix(word_index, word_embedding_model, embedding_dim):\n",
        "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "    for word, i in word_index.items():\n",
        "        if word in word_embedding_model.wv:\n",
        "            embedding_matrix[i] = word_embedding_model.wv[word]\n",
        "        else:\n",
        "            embedding_matrix[i] = np.zeros(embedding_dim)\n",
        "    return embedding_matrix\n",
        "\n",
        "def create_stacked_lstm_model(embedding_matrix, input_length, model_type):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=embedding_matrix.shape[0],\n",
        "                        output_dim=embedding_matrix.shape[1],\n",
        "                        weights=[embedding_matrix],\n",
        "                        input_length=input_length,\n",
        "                        trainable=False))\n",
        "    model.add(SpatialDropout1D(0.2))\n",
        "\n",
        "    if model_type == \"lstm\":\n",
        "        model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "        model.add(Bidirectional(LSTM(50, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)))\n",
        "    elif model_type == \"bilstm\":\n",
        "        model.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)))\n",
        "        model.add(Bidirectional(LSTM(50, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)))\n",
        "    elif model_type == \"gru\":\n",
        "        model.add(GRU(100, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "        model.add(GRU(50, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported model type. Choose 'lstm', 'bilstm', or 'gru'.\")\n",
        "\n",
        "    query = model.output\n",
        "    key = model.output\n",
        "    value = model.output\n",
        "\n",
        "    attention_layer = MultiHeadAttention(num_heads=4, key_dim=50)\n",
        "    attention_output = attention_layer(query=query, value=value, key=key)\n",
        "    attention_output = LayerNormalization()(attention_output)\n",
        "\n",
        "    # Concatenate LSTM output and attention output\n",
        "    combined_output = Concatenate()([model.output, attention_output])\n",
        "\n",
        "    # Apply GlobalAveragePooling1D to aggregate the sequence into a single vector\n",
        "    combined_output = GlobalAveragePooling1D()(combined_output)\n",
        "\n",
        "    combined_output = Dense(1, activation='sigmoid')(combined_output)\n",
        "\n",
        "    final_model = Model(inputs=model.input, outputs=combined_output)\n",
        "    final_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return final_model\n",
        "\n",
        "def train_and_evaluate_model(train_data, dev_data, word_embedding_type, model_type):\n",
        "    y_train = train_data[\"class_label\"].values\n",
        "    y_dev = dev_data[\"class_label\"].values\n",
        "\n",
        "    word_embedding_model = get_word_embedding_model(word_embedding_type)\n",
        "\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(train_data[\"tweet_text\"].tolist() + dev_data[\"tweet_text\"].tolist())\n",
        "    X_train_sequences = tokenizer.texts_to_sequences(train_data[\"tweet_text\"].tolist())\n",
        "    X_dev_sequences = tokenizer.texts_to_sequences(dev_data[\"tweet_text\"].tolist())\n",
        "\n",
        "    word_index = tokenizer.word_index\n",
        "    embedding_matrix = create_embedding_matrix(word_index, word_embedding_model, word_embedding_model.vector_size)\n",
        "\n",
        "    max_sequence_length = max(len(seq) for seq in X_train_sequences + X_dev_sequences)\n",
        "    X_train_padded = pad_sequences(X_train_sequences, maxlen=max_sequence_length)\n",
        "    X_dev_padded = pad_sequences(X_dev_sequences, maxlen=max_sequence_length)\n",
        "\n",
        "    # Handle data imbalance using random oversampling\n",
        "    ros = RandomOverSampler(random_state=42)\n",
        "    X_train_padded_resampled, y_train_resampled = ros.fit_resample(X_train_padded, y_train)\n",
        "\n",
        "    stacked_lstm_model = create_stacked_lstm_model(embedding_matrix, max_sequence_length, model_type)\n",
        "\n",
        "    # Early stopping callback\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    stacked_lstm_model.fit(X_train_padded_resampled, y_train_resampled, epochs=5, batch_size=32,\n",
        "                           validation_data=(X_dev_padded, y_dev),\n",
        "                           callbacks=[early_stopping])\n",
        "\n",
        "    dev_predictions = (stacked_lstm_model.predict(X_dev_padded, verbose=0) > 0.5).astype(\"int32\").flatten()\n",
        "    y_dev = y_dev.flatten()\n",
        "    f1score = f1_score(y_dev, dev_predictions)\n",
        "\n",
        "    print(f\"F1-score on Development Set: {f1score}\")\n",
        "    return stacked_lstm_model\n"
      ],
      "metadata": {
        "id": "Pcvs2-oewMNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_embedding_type = \"word2vec\"\n",
        "model_type = \"lstm\"\n",
        "train_data = df\n",
        "dev_data = df2\n",
        "\n",
        "stacked_lstm_model = train_and_evaluate_model(train_data, dev_data, word_embedding_type, model_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "YjO3yYFhwbkT",
        "outputId": "830a249e-b84d-4d2e-8af0-429db2de5e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "69/69 [==============================] - 95s 757ms/step - loss: 0.7062 - accuracy: 0.5463 - val_loss: 0.6669 - val_accuracy: 0.6030\n",
            "Epoch 2/5\n",
            "69/69 [==============================] - 42s 613ms/step - loss: 0.6902 - accuracy: 0.5344 - val_loss: 0.7172 - val_accuracy: 0.5330\n",
            "Epoch 3/5\n",
            "69/69 [==============================] - 42s 611ms/step - loss: 0.6926 - accuracy: 0.5477 - val_loss: 0.6826 - val_accuracy: 0.5690\n",
            "Epoch 4/5\n",
            "69/69 [==============================] - 41s 595ms/step - loss: 0.6841 - accuracy: 0.5546 - val_loss: 0.6436 - val_accuracy: 0.5870\n",
            "Epoch 5/5\n",
            "69/69 [==============================] - 40s 581ms/step - loss: 0.6869 - accuracy: 0.5505 - val_loss: 0.6828 - val_accuracy: 0.5680\n",
            "F1-score on Development Set: 0.5992578849721707\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'stacked_lstm_mode' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-87abaaa21fd0>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdev_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mstacked_lstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_embedding_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-faa7ac7625df>\u001b[0m in \u001b[0;36mtrain_and_evaluate_model\u001b[0;34m(train_data, dev_data, word_embedding_type, model_type)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"F1-score on Development Set: {f1score}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstacked_lstm_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'stacked_lstm_mode' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_embedding_type = \"word2vec\"\n",
        "model_type = \"bilstm\"\n",
        "train_data = df\n",
        "dev_data = df2\n",
        "stacked_lstm_model = train_and_evaluate_model(train_data, dev_data, word_embedding_type, model_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kpIzOOHwe23",
        "outputId": "dd9b9f25-fb7f-4eb4-e2b9-6283dd4ddba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "69/69 [==============================] - 82s 937ms/step - loss: 0.7045 - accuracy: 0.5436 - val_loss: 0.7990 - val_accuracy: 0.3980\n",
            "Epoch 2/5\n",
            "69/69 [==============================] - 58s 839ms/step - loss: 0.7042 - accuracy: 0.5243 - val_loss: 0.6516 - val_accuracy: 0.6060\n",
            "Epoch 3/5\n",
            "69/69 [==============================] - 61s 890ms/step - loss: 0.6849 - accuracy: 0.5596 - val_loss: 0.7230 - val_accuracy: 0.5280\n",
            "Epoch 4/5\n",
            "69/69 [==============================] - 61s 878ms/step - loss: 0.6863 - accuracy: 0.5550 - val_loss: 0.7346 - val_accuracy: 0.4740\n",
            "Epoch 5/5\n",
            "69/69 [==============================] - 65s 929ms/step - loss: 0.6941 - accuracy: 0.5257 - val_loss: 0.6704 - val_accuracy: 0.5900\n",
            "F1-score on Development Set: 0.42397660818713445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_embedding_type = \"word2vec\"\n",
        "model_type = \"gru\"\n",
        "train_data = df\n",
        "dev_data = df2\n",
        "stacked_lstm_model = train_and_evaluate_model(train_data, dev_data, word_embedding_type, model_type)"
      ],
      "metadata": {
        "id": "lZ7VldVHwhKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5361c801-07ac-4427-db83-145cd7891c79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "69/69 [==============================] - 39s 432ms/step - loss: 0.7053 - accuracy: 0.5491 - val_loss: 0.6953 - val_accuracy: 0.5130\n",
            "Epoch 2/5\n",
            "69/69 [==============================] - 29s 424ms/step - loss: 0.6862 - accuracy: 0.5440 - val_loss: 0.6635 - val_accuracy: 0.5650\n",
            "Epoch 3/5\n",
            "69/69 [==============================] - 29s 422ms/step - loss: 0.6851 - accuracy: 0.5573 - val_loss: 0.6885 - val_accuracy: 0.5260\n",
            "Epoch 4/5\n",
            "69/69 [==============================] - 29s 424ms/step - loss: 0.6830 - accuracy: 0.5725 - val_loss: 0.7189 - val_accuracy: 0.4830\n",
            "Epoch 5/5\n",
            "69/69 [==============================] - 30s 443ms/step - loss: 0.6867 - accuracy: 0.5601 - val_loss: 0.6631 - val_accuracy: 0.5890\n",
            "F1-score on Development Set: 0.5714285714285714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nNoSIZBb_fDp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}